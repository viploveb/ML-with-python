{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib        as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from sklearn.datasets        import load_boston\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "\n",
    "from IPython.display         import HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps involved in solving a problem with machine learning techniques-\n",
    "1. data preprocessing\n",
    "2. define 'error'\n",
    "3. split the data into two parts- trainig and testing data\n",
    "4. train the model\n",
    "5. prediction: obtain the predicted values for the given input and vizualize the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1 - DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "boston=load_boston()\n",
    "\n",
    "#description of datdset\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the data into pandas dataframes\n",
    "features = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(boston.target,columns=['target'])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(target['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(target['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate features and target into a simple dataframe\n",
    "#axis = 1 makes it concatenate column wise\n",
    "df = pd.concat([features,target],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(decimals =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlation between every on the data\n",
    "corr = df.corr('pearson')\n",
    "\n",
    "#take absolute values of correlation\n",
    "corrs =[abs(corr[attr]['target']) for attr in list (features)]\n",
    "\n",
    "#make a list of pairs [(corr, feature)]\n",
    "l = list(zip(corrs, list(features)))\n",
    "\n",
    "#sort the list of pairs in reverse/descending order\n",
    "# with the correlation value as the key for sorting\n",
    "l.sort(key = lambda x : x[0], reverse=True)\n",
    "\n",
    "# unzip pairs to two lists\n",
    "# zip(*l) - takes a list that looks like [[a,b,c],[d,e,f],[g,h,i]]\n",
    "# and returns [[a,d,g],...]\n",
    "corrs, labels = list(zip((*l)))\n",
    "\n",
    "#plot correlations with respect to the target variable as a bar graph\n",
    "index = np.arange(len(labels))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, corrs, width = 0.5)\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Correlation with the target variable')\n",
    "plt.xticks(index, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['DIS'].values\n",
    "Y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before noramlization\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler= MinMaxScaler()\n",
    "X = x_scaler.fit_transform(X.reshape(-1,1))\n",
    "X = X[:,-1]\n",
    "y_scaler = MinMaxScaler()\n",
    "Y = y_scaler.fit_transform(Y.reshape(-1,1))\n",
    "Y = Y[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after normalization\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 - DEFINE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(m, x, c, t):\n",
    "    N = x.size\n",
    "    e = sum(((m * x + c ) - t) **2)\n",
    "    return e * 1/(2 * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3 - SPLIT THE DATA ( training and testing )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 indicates 20% of the data is randomly sampled as testing data\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(m, x, c, t, learning_rate):\n",
    "    grad_m = sum(2 * ((m * x + c) - t) * x)\n",
    "    grad_c=sum(2 * ((m * x + c) - t))\n",
    "    m = m - grad_m * learning_rate\n",
    "    c = c - grad_c * learning_rate\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error threshold - if the error falls below the threshold, the gradient descent process is stopped and the weights are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(init_m, init_c, x, t, learning_rate, iterations, error_threshold):\n",
    "    m = init_m\n",
    "    c = init_c\n",
    "    error_values = list()\n",
    "    mc_values = list()\n",
    "    for i in range(iterations):\n",
    "        e = error(m, x, c, t)\n",
    "        if e < error_threshold:\n",
    "            print('error less than the threshold. stopping gradient descent')\n",
    "            break\n",
    "        error_values.append(e)\n",
    "        m, c = update(m, x, c, t, learning_rate)\n",
    "        mc_values.append((m, c))\n",
    "    return m, c, error_values, mc_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate- increasing the lr reduces the convergence time. But, if the learning rate is too high the model will overshoot the minima.\n",
    "\n",
    "iterations- no. of iterations must be large enough to allow the model to converge to a minima, but if it is too large, then the model becomes too specific to the training data thus causing overfitting, i.e, the model 'memorizes' the data instead of 'learning' the data.\n",
    "for this dataset if lr > 0.0025, it causes overflow. reduce the learning rate and observe the error values.\n",
    "\n",
    "error threshold- this value can be set to a max. value of erroe that is acceptable. when the error values goes below the threshold, the gradient descent is stopped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "init_m = 0.9\n",
    "init_c = 0\n",
    "learning_rate = 0.001\n",
    "iterations = 250\n",
    "error_threshold = 0.001\n",
    "\n",
    "m, c, error_values, mc_values = gradient_descent(init_m, init_c, xtrain, ytrain, learning_rate, iterations, error_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the number of iterations inreases, changes in the line are less noticable.\n",
    "# inorder to reduce the processing time fot the animation, it is advised to choose smaller values\n",
    "mc_values_anim = mc_values[0:250:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ln, = plt.plot([], [], 'ro-', animated=True)\n",
    "\n",
    "def init():\n",
    "    plt.scatter(xtest, ytest, color='g')\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    return ln,\n",
    "\n",
    "def update_frame(frame):\n",
    "    m , c = mc_values_anim[frame]\n",
    "    x1, y1 = -0.5, m * -.5 + c\n",
    "    x2, y2 = 1.5, m * 1.5 + c\n",
    "    ln.set_data([x1, x2], [y1, y2])\n",
    "    return ln,\n",
    "\n",
    "anim = FuncAnimation(fig, update_frame, frames=range(len(mc_values_anim)),\n",
    "                     init_func=init, blit=True)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the regressionline upon the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xtrain, ytrain, color='b')\n",
    "plt.plot(xtrain, (m * xtrain + c), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting error values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(error_values)), error_values)\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predictions on the test set as a vectorized operation\n",
    "predicted = (m * xtest) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute MSE for the predicted values on the testing set\n",
    "mean_squared_error(ytest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put xtest, ytest and predicted values into a single DataFrame so that we\n",
    "# can see the predicted values alongside the testing set\n",
    "p = pd.DataFrame(list(zip(xtest, ytest, predicted)), columns=['x','target_y', 'predicted_y'])\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PLOT THE PREDICTED VALUES AGAINST THE TARGET VALUES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xtest, ytest, color='b')\n",
    "plt.plot(xtest, predicted, color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    ".\n",
    "REVERT NORMALIZATION\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to change the shape to the shape that is required by the scalar\n",
    "predicted = predicted.reshape(-1, 1)\n",
    "xtest = xtest.reshape(-1, 1)\n",
    "ytest = ytest.reshape(-1 ,1)\n",
    "\n",
    "xtest_scaled = x_scaler.inverse_transform(xtest)\n",
    "ytest_scaled = y_scaler.inverse_transform(ytest)\n",
    "predicted_scaled = y_scaler.inverse_transform(predicted)\n",
    "\n",
    "# this is to remove the extra dimnesion\n",
    "xtest_scaled = xtest_scaled[:, -1]\n",
    "ytest_scaled = ytest_scaled[:, -1]\n",
    "predicted_scaled = predicted_scaled[:, -1]\n",
    "\n",
    "p = pd.DataFrame(list(zip(xtest_scaled, ytest_scaled,predicted_scaled)), columns=['x','target_y','predicted_y'])\n",
    "p = p.round(decimals = 2)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
